# ðŸ–ï¸ Hand Gesture Recognition with Hybrid Deep Learning

A hybrid deep learning approach combining **Swin Transformer**, **ResNet34**, and **BiLSTM** to recognize **18 static hand gestures** using the [HaGRID](https://github.com/hukenovs/hagrid) dataset with 98.03% accuracy. Built with PyTorch and Hugging Face Transformers.

---

## ðŸš€ Overview

This project leverages the strengths of transformer-based and convolutional neural networks for highly accurate hand gesture classification.

**Hybrid Architecture:**
- ðŸ§  **Swin Transformer** â€“ Token-based visual representation.
- ðŸ§  **ResNet34** â€“ Hierarchical CNN-based features.
- ðŸ” **BiLSTM** â€“ Sequential modeling of combined features.

---

## ðŸ—‚ï¸ Dataset

- **Name:** [HaGRID (Hand Gesture Recognition Image Dataset)](https://github.com/hukenovs/hagrid)
- **Size:** 120K+ gesture images
- **Classes:** 18 gesture categories
- **Input Format:** `.jpg` images with per-class annotation in `.json` files.

---

## ðŸ—ï¸ Model Architecture

```txt
Input Image (224x224)
â”‚
â”œâ”€â”€> Swin Transformer (Feature Vector: 768)
â”œâ”€â”€> ResNet34         (Feature Vector: 512)
â”‚
â””â”€â”€> Concatenation â†’ BiLSTM (bidirectional)
     â†“
     Fully Connected Layer â†’ Softmax (18 classes)
![WhatsApp Image 2025-05-26 at 07 56 48_0ada890d](https://github.com/user-attachments/assets/8f1dc323-a116-4716-af53-ffd2ed86053d)

